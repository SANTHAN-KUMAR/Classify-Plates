{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-03T18:00:03.768579Z",
     "iopub.status.busy": "2024-12-03T18:00:03.768332Z",
     "iopub.status.idle": "2024-12-03T18:00:04.212991Z",
     "shell.execute_reply": "2024-12-03T18:00:04.211753Z",
     "shell.execute_reply.started": "2024-12-03T18:00:03.768551Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/platesv2/sample_submission.csv\n",
      "/kaggle/input/platesv2/plates.zip\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T18:00:04.215277Z",
     "iopub.status.busy": "2024-12-03T18:00:04.214771Z",
     "iopub.status.idle": "2024-12-03T18:00:05.323518Z",
     "shell.execute_reply": "2024-12-03T18:00:05.322552Z",
     "shell.execute_reply.started": "2024-12-03T18:00:04.215235Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted files: ['plates', '__MACOSX']\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "zip_path = \"/kaggle/input/platesv2/plates.zip\"\n",
    "extract_path = \"/kaggle/working/plates\"\n",
    "\n",
    "# Extract the zip file\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "\n",
    "# Verify extraction\n",
    "print(\"Extracted files:\", os.listdir(extract_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T18:00:05.324784Z",
     "iopub.status.busy": "2024-12-03T18:00:05.324529Z",
     "iopub.status.idle": "2024-12-03T18:00:05.332722Z",
     "shell.execute_reply": "2024-12-03T18:00:05.331851Z",
     "shell.execute_reply.started": "2024-12-03T18:00:05.324758Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cleaned', '.DS_Store', 'dirty']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = os.listdir(\"/kaggle/working/plates/plates/train\")\n",
    "test_dir = os.listdir(\"/kaggle/working/plates/plates/test\")\n",
    "\n",
    "train_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T18:00:05.334970Z",
     "iopub.status.busy": "2024-12-03T18:00:05.334674Z",
     "iopub.status.idle": "2024-12-03T18:00:09.481330Z",
     "shell.execute_reply": "2024-12-03T18:00:09.480473Z",
     "shell.execute_reply.started": "2024-12-03T18:00:05.334946Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['cleaned', 'dirty']\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define the correct path to the train folder\n",
    "train_dir = \"/kaggle/working/plates/plates/train\"\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),   # Resize all images\n",
    "    transforms.ToTensor()            # Convert to Tensor\n",
    "])\n",
    "\n",
    "# Load the training dataset\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "\n",
    "# Print classes to verify\n",
    "print(\"Classes:\", train_dataset.classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T18:00:09.483231Z",
     "iopub.status.busy": "2024-12-03T18:00:09.482848Z",
     "iopub.status.idle": "2024-12-03T18:00:09.584975Z",
     "shell.execute_reply": "2024-12-03T18:00:09.584111Z",
     "shell.execute_reply.started": "2024-12-03T18:00:09.483204Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch of images: torch.Size([4, 3, 224, 224])\n",
      "Batch of labels: tensor([0, 0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create DataLoader for the training dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# Check some sample data\n",
    "data_iter = iter(train_loader)\n",
    "images, labels = next(data_iter)\n",
    "print(\"Batch of images:\", images.shape)\n",
    "print(\"Batch of labels:\", labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T18:00:09.586271Z",
     "iopub.status.busy": "2024-12-03T18:00:09.586007Z",
     "iopub.status.idle": "2024-12-03T18:00:10.548069Z",
     "shell.execute_reply": "2024-12-03T18:00:10.547359Z",
     "shell.execute_reply.started": "2024-12-03T18:00:09.586246Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 201MB/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "\n",
    "# Load ResNet18 model\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Modify the final layer for 2 classes (dirty and clean)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(num_features, 2)  # Output size = 2\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T18:00:42.093796Z",
     "iopub.status.busy": "2024-12-03T18:00:42.093467Z",
     "iopub.status.idle": "2024-12-03T18:00:42.100258Z",
     "shell.execute_reply": "2024-12-03T18:00:42.099387Z",
     "shell.execute_reply.started": "2024-12-03T18:00:42.093766Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.001\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T18:01:09.932621Z",
     "iopub.status.busy": "2024-12-03T18:01:09.932288Z",
     "iopub.status.idle": "2024-12-03T18:01:22.398547Z",
     "shell.execute_reply": "2024-12-03T18:01:22.397640Z",
     "shell.execute_reply.started": "2024-12-03T18:01:09.932591Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.6352248787879944\n",
      "Epoch 2/50, Loss: 0.5107301563024521\n",
      "Epoch 3/50, Loss: 0.5132587671279907\n",
      "Epoch 4/50, Loss: 0.4414399921894073\n",
      "Epoch 5/50, Loss: 0.4324199497699738\n",
      "Epoch 6/50, Loss: 0.40569522976875305\n",
      "Epoch 7/50, Loss: 0.4118296250700951\n",
      "Epoch 8/50, Loss: 0.452118257433176\n",
      "Epoch 9/50, Loss: 0.31927633583545684\n",
      "Epoch 10/50, Loss: 0.3165430337190628\n",
      "Epoch 11/50, Loss: 0.33702687323093417\n",
      "Epoch 12/50, Loss: 0.3507377587258816\n",
      "Epoch 13/50, Loss: 0.3134429931640625\n",
      "Epoch 14/50, Loss: 0.34882262647151946\n",
      "Epoch 15/50, Loss: 0.32602500542998314\n",
      "Epoch 16/50, Loss: 0.34604691416025163\n",
      "Epoch 17/50, Loss: 0.2711860820651054\n",
      "Epoch 18/50, Loss: 0.2708060421049595\n",
      "Epoch 19/50, Loss: 0.3262872636318207\n",
      "Epoch 20/50, Loss: 0.22157092541456222\n",
      "Epoch 21/50, Loss: 0.21189157366752626\n",
      "Epoch 22/50, Loss: 0.23923047557473182\n",
      "Epoch 23/50, Loss: 0.2114149495959282\n",
      "Epoch 24/50, Loss: 0.2825522720813751\n",
      "Epoch 25/50, Loss: 0.31170803755521775\n",
      "Epoch 26/50, Loss: 0.5270017474889755\n",
      "Epoch 27/50, Loss: 0.2820572957396507\n",
      "Epoch 28/50, Loss: 0.4292137950658798\n",
      "Epoch 29/50, Loss: 0.3251569621264935\n",
      "Epoch 30/50, Loss: 0.16891842782497407\n",
      "Epoch 31/50, Loss: 0.33992794826626777\n",
      "Epoch 32/50, Loss: 0.22790351137518883\n",
      "Epoch 33/50, Loss: 0.24796035885810852\n",
      "Epoch 34/50, Loss: 0.3640894487500191\n",
      "Epoch 35/50, Loss: 0.36227173656225203\n",
      "Epoch 36/50, Loss: 0.1535164812579751\n",
      "Epoch 37/50, Loss: 0.31143072694540025\n",
      "Epoch 38/50, Loss: 0.2663122616708279\n",
      "Epoch 39/50, Loss: 0.20320394709706308\n",
      "Epoch 40/50, Loss: 0.3616890698671341\n",
      "Epoch 41/50, Loss: 0.19599779620766639\n",
      "Epoch 42/50, Loss: 0.365081874281168\n",
      "Epoch 43/50, Loss: 0.35979450941085817\n",
      "Epoch 44/50, Loss: 0.26682375073432923\n",
      "Epoch 45/50, Loss: 0.2109085388481617\n",
      "Epoch 46/50, Loss: 0.33444128558039665\n",
      "Epoch 47/50, Loss: 0.23099133744835854\n",
      "Epoch 48/50, Loss: 0.2211947947740555\n",
      "Epoch 49/50, Loss: 0.15268484726548195\n",
      "Epoch 50/50, Loss: 0.14510790556669234\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T18:05:14.323086Z",
     "iopub.status.busy": "2024-12-03T18:05:14.322711Z",
     "iopub.status.idle": "2024-12-03T18:05:16.268529Z",
     "shell.execute_reply": "2024-12-03T18:05:16.267607Z",
     "shell.execute_reply.started": "2024-12-03T18:05:14.323046Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 744 test images.\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Define the test folder path\n",
    "test_dir = \"/kaggle/working/plates/plates/test\"\n",
    "\n",
    "# Define transformations (same as train)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Load test images manually\n",
    "test_images = []\n",
    "test_ids = []\n",
    "\n",
    "for img_name in os.listdir(test_dir):\n",
    "    img_path = os.path.join(test_dir, img_name)\n",
    "    image = Image.open(img_path).convert(\"RGB\")  # Ensure 3 channels (RGB)\n",
    "    image = transform(image)  # Apply transformations\n",
    "    test_images.append(image)\n",
    "    test_ids.append(img_name.split('.')[0])  # Extract ID from filename\n",
    "\n",
    "print(f\"Loaded {len(test_images)} test images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T18:10:09.633441Z",
     "iopub.status.busy": "2024-12-03T18:10:09.633106Z",
     "iopub.status.idle": "2024-12-03T18:10:12.901402Z",
     "shell.execute_reply": "2024-12-03T18:10:12.900491Z",
     "shell.execute_reply.started": "2024-12-03T18:10:09.633411Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 744 test images.\n",
      "Submission saved!\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "\n",
    "# Define the test folder path\n",
    "test_dir = \"/kaggle/working/plates/plates/test\"\n",
    "\n",
    "# Define transformations (same as train)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Load test images manually\n",
    "test_images = []\n",
    "test_ids = []\n",
    "\n",
    "for img_name in os.listdir(test_dir):\n",
    "    img_path = os.path.join(test_dir, img_name)\n",
    "    \n",
    "    # Skip non-image files like .DS_Store\n",
    "    if img_name.startswith('.') or not img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        continue\n",
    "    \n",
    "    image = Image.open(img_path).convert(\"RGB\")  # Ensure 3 channels (RGB)\n",
    "    image = transform(image)  # Apply transformations\n",
    "    test_images.append(image)\n",
    "    test_ids.append(img_name.split('.')[0])  # Extract ID from filename\n",
    "\n",
    "print(f\"Loaded {len(test_images)} test images.\")\n",
    "\n",
    "# Convert list to tensor\n",
    "test_images = torch.stack(test_images)\n",
    "\n",
    "# Create a TensorDataset for test data\n",
    "test_dataset = TensorDataset(test_images)\n",
    "\n",
    "# Create a DataLoader for batching (batch_size 8)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# List to store predictions\n",
    "predictions = []\n",
    "\n",
    "# Inference loop for test dataset\n",
    "with torch.no_grad():  # No need to track gradients during inference\n",
    "    for images in test_loader:\n",
    "        images = images[0].to(device)  # Images are wrapped in a tuple, so access images[0]\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        predictions.extend(preds.cpu().numpy())\n",
    "\n",
    "# Convert predictions to 'clean' or 'dirty' labels\n",
    "predicted_labels = ['clean' if pred == 0 else 'dirty' for pred in predictions]\n",
    "\n",
    "# Create the submission DataFrame\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'label': predicted_labels\n",
    "})\n",
    "\n",
    "# Save the predictions to CSV\n",
    "submission_df.to_csv('/kaggle/working/submission.csv', index=False)\n",
    "print(\"Submission saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T18:12:52.895228Z",
     "iopub.status.busy": "2024-12-03T18:12:52.894543Z",
     "iopub.status.idle": "2024-12-03T18:12:52.899092Z",
     "shell.execute_reply": "2024-12-03T18:12:52.898048Z",
     "shell.execute_reply.started": "2024-12-03T18:12:52.895193Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "############   ABOVE CODE ACCURACY IS ONLY 59  ###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T18:12:56.494373Z",
     "iopub.status.busy": "2024-12-03T18:12:56.494041Z",
     "iopub.status.idle": "2024-12-03T18:12:57.003672Z",
     "shell.execute_reply": "2024-12-03T18:12:57.002973Z",
     "shell.execute_reply.started": "2024-12-03T18:12:56.494345Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms, models\n",
    "from sklearn.metrics import classification_report\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T18:13:07.889279Z",
     "iopub.status.busy": "2024-12-03T18:13:07.888724Z",
     "iopub.status.idle": "2024-12-03T18:13:07.893399Z",
     "shell.execute_reply": "2024-12-03T18:13:07.892515Z",
     "shell.execute_reply.started": "2024-12-03T18:13:07.889248Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T18:13:13.620349Z",
     "iopub.status.busy": "2024-12-03T18:13:13.619704Z",
     "iopub.status.idle": "2024-12-03T18:13:13.626129Z",
     "shell.execute_reply": "2024-12-03T18:13:13.625239Z",
     "shell.execute_reply.started": "2024-12-03T18:13:13.620314Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),   # Data augmentation\n",
    "    transforms.RandomRotation(30),       # Data augmentation\n",
    "    transforms.RandomAffine(15),         # Data augmentation\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalization for pre-trained models\n",
    "])\n",
    "\n",
    "# Define transformations for test (no augmentation, only resizing)\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T18:13:20.420121Z",
     "iopub.status.busy": "2024-12-03T18:13:20.419291Z",
     "iopub.status.idle": "2024-12-03T18:13:22.950584Z",
     "shell.execute_reply": "2024-12-03T18:13:22.949609Z",
     "shell.execute_reply.started": "2024-12-03T18:13:20.420089Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define train directory\n",
    "train_dir = \"/kaggle/working/plates/plates/train\"\n",
    "\n",
    "# Load training data\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "\n",
    "# Split dataset into training and validation sets (80% training, 20% validation)\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# DataLoader for training, validation, and test\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Define test directory and test data\n",
    "test_dir = \"/kaggle/working/plates/plates/test\"\n",
    "test_images = []\n",
    "test_ids = []\n",
    "\n",
    "for img_name in os.listdir(test_dir):\n",
    "    img_path = os.path.join(test_dir, img_name)\n",
    "    try:\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        image = test_transform(image)  # Apply transformations\n",
    "        test_images.append(image)\n",
    "        test_ids.append(img_name.split('.')[0])  # Extract ID from filename\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "# Create a DataLoader for test dataset\n",
    "test_images_tensor = torch.stack(test_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T18:13:31.779530Z",
     "iopub.status.busy": "2024-12-03T18:13:31.779185Z",
     "iopub.status.idle": "2024-12-03T18:13:32.038877Z",
     "shell.execute_reply": "2024-12-03T18:13:32.037961Z",
     "shell.execute_reply.started": "2024-12-03T18:13:31.779499Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained ResNet18 model and modify the final layer for 2 classes\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)  # Adjust for 2 classes (clean, dirty)\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T18:14:03.724410Z",
     "iopub.status.busy": "2024-12-03T18:14:03.723710Z",
     "iopub.status.idle": "2024-12-03T18:14:03.729058Z",
     "shell.execute_reply": "2024-12-03T18:14:03.728103Z",
     "shell.execute_reply.started": "2024-12-03T18:14:03.724376Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Learning rate scheduler (decreases LR after 7 epochs)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T18:14:09.995044Z",
     "iopub.status.busy": "2024-12-03T18:14:09.994181Z",
     "iopub.status.idle": "2024-12-03T18:14:10.003411Z",
     "shell.execute_reply": "2024-12-03T18:14:10.002510Z",
     "shell.execute_reply.started": "2024-12-03T18:14:09.994996Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to train the model\n",
    "def train_model(model, train_loader, val_loader, optimizer, criterion, scheduler, num_epochs=10):\n",
    "    best_acc = 0.0  # To keep track of the best accuracy during training\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "        running_loss = 0.0\n",
    "        correct_preds = 0\n",
    "        total_preds = 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Zero gradients, perform a backward pass, and update the weights\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct_preds += torch.sum(preds == labels).item()\n",
    "            total_preds += labels.size(0)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Print statistics for each epoch\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = correct_preds / total_preds\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}\")\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        val_correct_preds = 0\n",
    "        val_total_preds = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct_preds += torch.sum(preds == labels).item()\n",
    "                val_total_preds += labels.size(0)\n",
    "\n",
    "        val_acc = val_correct_preds / val_total_preds\n",
    "        print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "        # Save the best model based on validation accuracy\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "        scheduler.step()  # Step the learning rate scheduler\n",
    "\n",
    "    print(f\"Best Validation Accuracy: {best_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T18:14:42.784495Z",
     "iopub.status.busy": "2024-12-03T18:14:42.784189Z",
     "iopub.status.idle": "2024-12-03T18:15:08.911479Z",
     "shell.execute_reply": "2024-12-03T18:15:08.910565Z",
     "shell.execute_reply.started": "2024-12-03T18:14:42.784470Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.4124, Accuracy: 0.8438\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 2/100, Loss: 0.3377, Accuracy: 0.8750\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 3/100, Loss: 0.3791, Accuracy: 0.9062\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 4/100, Loss: 0.3419, Accuracy: 0.9062\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 5/100, Loss: 0.1942, Accuracy: 0.9688\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 6/100, Loss: 0.2656, Accuracy: 0.9062\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 7/100, Loss: 0.2738, Accuracy: 0.8750\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 8/100, Loss: 0.3552, Accuracy: 0.8438\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 9/100, Loss: 0.2258, Accuracy: 0.9062\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 10/100, Loss: 0.4306, Accuracy: 0.8438\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 11/100, Loss: 0.2797, Accuracy: 0.8125\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 12/100, Loss: 0.2837, Accuracy: 0.8125\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 13/100, Loss: 0.2313, Accuracy: 0.9688\n",
      "Validation Accuracy: 0.5000\n",
      "Epoch 14/100, Loss: 0.2501, Accuracy: 0.9062\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 15/100, Loss: 0.2353, Accuracy: 0.8750\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 16/100, Loss: 0.2348, Accuracy: 0.9688\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 17/100, Loss: 0.2060, Accuracy: 0.9062\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 18/100, Loss: 0.2548, Accuracy: 0.8750\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 19/100, Loss: 0.3357, Accuracy: 0.8438\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 20/100, Loss: 0.2551, Accuracy: 0.9062\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 21/100, Loss: 0.2440, Accuracy: 0.8750\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 22/100, Loss: 0.3126, Accuracy: 0.9062\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 23/100, Loss: 0.3697, Accuracy: 0.8750\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 24/100, Loss: 0.1898, Accuracy: 0.9375\n",
      "Validation Accuracy: 0.5000\n",
      "Epoch 25/100, Loss: 0.2615, Accuracy: 0.8750\n",
      "Validation Accuracy: 0.5000\n",
      "Epoch 26/100, Loss: 0.2511, Accuracy: 0.9062\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 27/100, Loss: 0.2299, Accuracy: 0.9062\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 28/100, Loss: 0.3349, Accuracy: 0.8750\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 29/100, Loss: 0.2987, Accuracy: 0.8125\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 30/100, Loss: 0.2439, Accuracy: 0.8750\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 31/100, Loss: 0.2530, Accuracy: 0.9062\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 32/100, Loss: 0.3007, Accuracy: 0.8125\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 33/100, Loss: 0.3122, Accuracy: 0.9062\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 34/100, Loss: 0.2846, Accuracy: 0.8125\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 35/100, Loss: 0.3226, Accuracy: 0.7812\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 36/100, Loss: 0.2149, Accuracy: 0.9375\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 37/100, Loss: 0.2699, Accuracy: 0.8750\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 38/100, Loss: 0.3836, Accuracy: 0.8125\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 39/100, Loss: 0.2330, Accuracy: 0.9062\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 40/100, Loss: 0.2137, Accuracy: 0.9688\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 41/100, Loss: 0.2553, Accuracy: 0.9062\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 42/100, Loss: 0.2567, Accuracy: 0.8750\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 43/100, Loss: 0.1863, Accuracy: 0.9688\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 44/100, Loss: 0.2365, Accuracy: 0.9375\n",
      "Validation Accuracy: 0.5000\n",
      "Epoch 45/100, Loss: 0.2216, Accuracy: 0.9375\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 46/100, Loss: 0.1966, Accuracy: 0.9375\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 47/100, Loss: 0.2692, Accuracy: 0.8750\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 48/100, Loss: 0.3102, Accuracy: 0.8750\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 49/100, Loss: 0.2518, Accuracy: 0.8750\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 50/100, Loss: 0.3308, Accuracy: 0.8125\n",
      "Validation Accuracy: 0.5000\n",
      "Epoch 51/100, Loss: 0.2057, Accuracy: 0.9375\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 52/100, Loss: 0.2203, Accuracy: 0.9062\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 53/100, Loss: 0.3639, Accuracy: 0.8438\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 54/100, Loss: 0.3516, Accuracy: 0.8125\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 55/100, Loss: 0.2053, Accuracy: 0.9375\n",
      "Validation Accuracy: 0.7500\n",
      "Epoch 56/100, Loss: 0.2511, Accuracy: 0.9375\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 57/100, Loss: 0.1998, Accuracy: 0.9688\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 58/100, Loss: 0.1971, Accuracy: 0.9688\n",
      "Validation Accuracy: 0.5000\n",
      "Epoch 59/100, Loss: 0.2755, Accuracy: 0.9688\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 60/100, Loss: 0.2609, Accuracy: 0.9062\n",
      "Validation Accuracy: 0.5000\n",
      "Epoch 61/100, Loss: 0.2182, Accuracy: 0.9375\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 62/100, Loss: 0.1893, Accuracy: 0.9688\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 63/100, Loss: 0.3377, Accuracy: 0.8125\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 64/100, Loss: 0.2221, Accuracy: 0.9375\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 65/100, Loss: 0.3301, Accuracy: 0.8125\n",
      "Validation Accuracy: 0.7500\n",
      "Epoch 66/100, Loss: 0.2564, Accuracy: 0.9062\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 67/100, Loss: 0.2293, Accuracy: 0.9375\n",
      "Validation Accuracy: 0.5000\n",
      "Epoch 68/100, Loss: 0.2526, Accuracy: 0.9375\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 69/100, Loss: 0.2324, Accuracy: 0.9688\n",
      "Validation Accuracy: 0.5000\n",
      "Epoch 70/100, Loss: 0.2458, Accuracy: 0.9375\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 71/100, Loss: 0.2191, Accuracy: 0.9062\n",
      "Validation Accuracy: 0.5000\n",
      "Epoch 72/100, Loss: 0.3120, Accuracy: 0.8438\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 73/100, Loss: 0.2164, Accuracy: 0.9062\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 74/100, Loss: 0.2016, Accuracy: 0.9375\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 75/100, Loss: 0.1855, Accuracy: 0.9688\n",
      "Validation Accuracy: 0.5000\n",
      "Epoch 76/100, Loss: 0.2510, Accuracy: 0.9062\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 77/100, Loss: 0.2228, Accuracy: 0.9375\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 78/100, Loss: 0.2343, Accuracy: 0.8750\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 79/100, Loss: 0.2090, Accuracy: 0.9062\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 80/100, Loss: 0.4396, Accuracy: 0.8125\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 81/100, Loss: 0.2144, Accuracy: 0.9062\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 82/100, Loss: 0.2209, Accuracy: 0.9375\n",
      "Validation Accuracy: 0.5000\n",
      "Epoch 83/100, Loss: 0.2156, Accuracy: 0.9062\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 84/100, Loss: 0.2138, Accuracy: 0.9375\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 85/100, Loss: 0.3888, Accuracy: 0.8125\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 86/100, Loss: 0.3471, Accuracy: 0.8438\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 87/100, Loss: 0.1914, Accuracy: 0.9688\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 88/100, Loss: 0.2515, Accuracy: 0.8438\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 89/100, Loss: 0.3471, Accuracy: 0.8438\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 90/100, Loss: 0.2691, Accuracy: 0.8438\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 91/100, Loss: 0.3355, Accuracy: 0.8438\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 92/100, Loss: 0.2718, Accuracy: 0.9375\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 93/100, Loss: 0.2426, Accuracy: 0.9375\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 94/100, Loss: 0.2661, Accuracy: 0.9062\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 95/100, Loss: 0.3079, Accuracy: 0.8438\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 96/100, Loss: 0.4304, Accuracy: 0.8125\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 97/100, Loss: 0.2472, Accuracy: 0.8750\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 98/100, Loss: 0.2374, Accuracy: 0.9375\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 99/100, Loss: 0.1978, Accuracy: 1.0000\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 100/100, Loss: 0.2282, Accuracy: 0.9375\n",
      "Validation Accuracy: 0.6250\n",
      "Best Validation Accuracy: 0.7500\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train_model(model, train_loader, val_loader, optimizer, criterion, scheduler, num_epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T18:15:51.269761Z",
     "iopub.status.busy": "2024-12-03T18:15:51.269118Z",
     "iopub.status.idle": "2024-12-03T18:15:53.658998Z",
     "shell.execute_reply": "2024-12-03T18:15:53.658127Z",
     "shell.execute_reply.started": "2024-12-03T18:15:51.269727Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/3064993140.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_model.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved!\n"
     ]
    }
   ],
   "source": [
    "# Load the best model\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Inference on test images\n",
    "test_preds = []\n",
    "with torch.no_grad():\n",
    "    for image in test_images_tensor:\n",
    "        image = image.unsqueeze(0).to(device)  # Add batch dimension\n",
    "        output = model(image)\n",
    "        _, pred = torch.max(output, 1)\n",
    "        test_preds.append(pred.item())\n",
    "\n",
    "# Convert predictions to labels\n",
    "predicted_labels = ['clean' if pred == 0 else 'dirty' for pred in test_preds]\n",
    "\n",
    "# Create a submission DataFrame\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'label': predicted_labels\n",
    "})\n",
    "\n",
    "# Save the predictions to CSV\n",
    "submission_df.to_csv('/kaggle/working/submission_plates.csv', index=False)\n",
    "print(\"Submission saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T18:18:29.560356Z",
     "iopub.status.busy": "2024-12-03T18:18:29.560026Z",
     "iopub.status.idle": "2024-12-03T18:18:29.564310Z",
     "shell.execute_reply": "2024-12-03T18:18:29.563403Z",
     "shell.execute_reply.started": "2024-12-03T18:18:29.560328Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "###############  ABOVE CODE'S ACCURACY IS TOO WORST - 21 ###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T18:18:41.864981Z",
     "iopub.status.busy": "2024-12-03T18:18:41.864137Z",
     "iopub.status.idle": "2024-12-03T18:18:55.270980Z",
     "shell.execute_reply": "2024-12-03T18:18:55.270038Z",
     "shell.execute_reply.started": "2024-12-03T18:18:41.864945Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.7863, Accuracy: 0.6875\n",
      "Validation Accuracy: 0.5000\n",
      "Epoch 2/50, Loss: 0.8317, Accuracy: 0.8125\n",
      "Validation Accuracy: 0.3750\n",
      "Epoch 3/50, Loss: 1.1579, Accuracy: 0.7500\n",
      "Validation Accuracy: 0.1250\n",
      "Epoch 4/50, Loss: 0.5298, Accuracy: 0.7812\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 5/50, Loss: 0.1951, Accuracy: 0.9062\n",
      "Validation Accuracy: 0.7500\n",
      "Epoch 6/50, Loss: 0.1358, Accuracy: 0.9375\n",
      "Validation Accuracy: 0.5000\n",
      "Epoch 7/50, Loss: 0.1809, Accuracy: 0.9375\n",
      "Validation Accuracy: 0.5000\n",
      "Epoch 8/50, Loss: 0.2208, Accuracy: 0.9062\n",
      "Validation Accuracy: 0.5000\n",
      "Epoch 9/50, Loss: 0.1597, Accuracy: 0.9375\n",
      "Validation Accuracy: 0.5000\n",
      "Epoch 10/50, Loss: 0.0891, Accuracy: 0.9688\n",
      "Validation Accuracy: 0.5000\n",
      "Epoch 11/50, Loss: 0.0671, Accuracy: 1.0000\n",
      "Validation Accuracy: 0.5000\n",
      "Epoch 12/50, Loss: 0.1259, Accuracy: 0.9375\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 13/50, Loss: 0.0736, Accuracy: 1.0000\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 14/50, Loss: 0.1430, Accuracy: 0.9688\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 15/50, Loss: 0.0560, Accuracy: 0.9688\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 16/50, Loss: 0.0457, Accuracy: 1.0000\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 17/50, Loss: 0.0619, Accuracy: 1.0000\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 18/50, Loss: 0.0257, Accuracy: 1.0000\n",
      "Validation Accuracy: 0.5000\n",
      "Epoch 19/50, Loss: 0.0866, Accuracy: 1.0000\n",
      "Validation Accuracy: 0.5000\n",
      "Epoch 20/50, Loss: 0.0806, Accuracy: 0.9688\n",
      "Validation Accuracy: 0.5000\n",
      "Epoch 21/50, Loss: 0.0592, Accuracy: 1.0000\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 22/50, Loss: 0.0679, Accuracy: 1.0000\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 23/50, Loss: 0.0893, Accuracy: 0.9688\n",
      "Validation Accuracy: 0.5000\n",
      "Epoch 24/50, Loss: 0.0528, Accuracy: 1.0000\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 25/50, Loss: 0.0392, Accuracy: 1.0000\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 26/50, Loss: 0.0466, Accuracy: 1.0000\n",
      "Validation Accuracy: 0.3750\n",
      "Epoch 27/50, Loss: 0.0433, Accuracy: 1.0000\n",
      "Validation Accuracy: 0.5000\n",
      "Epoch 28/50, Loss: 0.0390, Accuracy: 1.0000\n",
      "Validation Accuracy: 0.5000\n",
      "Epoch 29/50, Loss: 0.0691, Accuracy: 1.0000\n",
      "Validation Accuracy: 0.5000\n",
      "Epoch 30/50, Loss: 0.2090, Accuracy: 0.8750\n",
      "Validation Accuracy: 0.5000\n",
      "Epoch 31/50, Loss: 0.0929, Accuracy: 0.9688\n",
      "Validation Accuracy: 0.5000\n",
      "Epoch 32/50, Loss: 0.0459, Accuracy: 1.0000\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 33/50, Loss: 0.0350, Accuracy: 1.0000\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 34/50, Loss: 0.0316, Accuracy: 1.0000\n",
      "Validation Accuracy: 0.5000\n",
      "Epoch 35/50, Loss: 0.0596, Accuracy: 0.9688\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 36/50, Loss: 0.0834, Accuracy: 0.9688\n",
      "Validation Accuracy: 0.5000\n",
      "Epoch 37/50, Loss: 0.0801, Accuracy: 1.0000\n",
      "Validation Accuracy: 0.5000\n",
      "Epoch 38/50, Loss: 0.0212, Accuracy: 1.0000\n",
      "Validation Accuracy: 0.5000\n",
      "Epoch 39/50, Loss: 0.0358, Accuracy: 1.0000\n",
      "Validation Accuracy: 0.5000\n",
      "Epoch 40/50, Loss: 0.0472, Accuracy: 1.0000\n",
      "Validation Accuracy: 0.5000\n",
      "Epoch 41/50, Loss: 0.0709, Accuracy: 1.0000\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 42/50, Loss: 0.0266, Accuracy: 1.0000\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 43/50, Loss: 0.0386, Accuracy: 1.0000\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 44/50, Loss: 0.0660, Accuracy: 1.0000\n",
      "Validation Accuracy: 0.5000\n",
      "Epoch 45/50, Loss: 0.5363, Accuracy: 0.8750\n",
      "Validation Accuracy: 0.5000\n",
      "Epoch 46/50, Loss: 0.0586, Accuracy: 0.9688\n",
      "Validation Accuracy: 0.5000\n",
      "Epoch 47/50, Loss: 0.0472, Accuracy: 1.0000\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 48/50, Loss: 0.0225, Accuracy: 1.0000\n",
      "Validation Accuracy: 0.5000\n",
      "Epoch 49/50, Loss: 0.0484, Accuracy: 1.0000\n",
      "Validation Accuracy: 0.6250\n",
      "Epoch 50/50, Loss: 0.3861, Accuracy: 0.8750\n",
      "Validation Accuracy: 0.6250\n",
      "Best Validation Accuracy: 0.7500\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms, models\n",
    "from sklearn.metrics import classification_report\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Check if GPU is available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define transformations (augmentation for training and normalization)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to fit the model\n",
    "    transforms.RandomHorizontalFlip(),   # Augment the data by flipping\n",
    "    transforms.RandomRotation(30),       # Augment the data by rotating\n",
    "    transforms.RandomAffine(15),         # Augment the data by affine transformation\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize with mean & std\n",
    "])\n",
    "\n",
    "# Test data transformations (no augmentation, only resizing)\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Define train directory and load dataset\n",
    "train_dir = \"/kaggle/working/plates/plates/train\"\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "\n",
    "# Split dataset into training and validation sets\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# DataLoader for training and validation datasets\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Load the pre-trained ResNet18 model\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)  # Adjust for 2 classes (clean, dirty)\n",
    "model = model.to(device)  # Move model to GPU or CPU\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Learning rate scheduler (optional for better optimization)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# Function to train the model\n",
    "def train_model(model, train_loader, val_loader, optimizer, criterion, scheduler, num_epochs=10):\n",
    "    best_acc = 0.0  # Best accuracy to track best model\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        running_loss = 0.0\n",
    "        correct_preds = 0\n",
    "        total_preds = 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Zero gradients, perform a backward pass, and update the weights\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct_preds += torch.sum(preds == labels).item()\n",
    "            total_preds += labels.size(0)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Print statistics for each epoch\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = correct_preds / total_preds\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}\")\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        val_correct_preds = 0\n",
    "        val_total_preds = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct_preds += torch.sum(preds == labels).item()\n",
    "                val_total_preds += labels.size(0)\n",
    "\n",
    "        val_acc = val_correct_preds / val_total_preds\n",
    "        print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "        # Save the best model based on validation accuracy\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "        scheduler.step()  # Step the learning rate scheduler\n",
    "\n",
    "    print(f\"Best Validation Accuracy: {best_acc:.4f}\")\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, val_loader, optimizer, criterion, scheduler, num_epochs=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T18:19:00.775778Z",
     "iopub.status.busy": "2024-12-03T18:19:00.775427Z",
     "iopub.status.idle": "2024-12-03T18:19:05.493697Z",
     "shell.execute_reply": "2024-12-03T18:19:05.492850Z",
     "shell.execute_reply.started": "2024-12-03T18:19:00.775740Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/4266489762.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_model.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved!\n"
     ]
    }
   ],
   "source": [
    "# Load the best model for inference\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Define test directory\n",
    "test_dir = \"/kaggle/working/plates/plates/test\"\n",
    "test_images = []\n",
    "test_ids = []\n",
    "\n",
    "# Preprocess the test data\n",
    "for img_name in os.listdir(test_dir):\n",
    "    img_path = os.path.join(test_dir, img_name)\n",
    "    try:\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        image = test_transform(image)\n",
    "        test_images.append(image)\n",
    "        test_ids.append(img_name.split('.')[0])  # Extract ID from filename\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "# Convert to tensor\n",
    "test_images_tensor = torch.stack(test_images)\n",
    "\n",
    "# Inference on test data\n",
    "test_preds = []\n",
    "with torch.no_grad():\n",
    "    for image in test_images_tensor:\n",
    "        image = image.unsqueeze(0).to(device)  # Add batch dimension\n",
    "        output = model(image)\n",
    "        _, pred = torch.max(output, 1)\n",
    "        test_preds.append(pred.item())\n",
    "\n",
    "# Convert predictions to 'clean' or 'dirty' labels\n",
    "predicted_labels = ['clean' if pred == 0 else 'dirty' for pred in test_preds]\n",
    "\n",
    "# Create a submission DataFrame\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'label': predicted_labels\n",
    "})\n",
    "\n",
    "# Save the predictions to CSV\n",
    "submission_df.to_csv('/kaggle/working/submission.csv', index=False)\n",
    "print(\"Submission saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 565187,
     "sourceId": 15282,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
